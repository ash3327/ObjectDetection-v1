{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1159,
   "id": "68fa686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference: https://www.youtube.com/watch?v=WgPbbWmnXJ8&ab_channel=Murtaza%27sWorkshop-RoboticsandAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab737d",
   "metadata": {},
   "source": [
    "# 1. Preparing Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84a710",
   "metadata": {},
   "source": [
    "## 1.1 Initialization of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa1d108",
   "metadata": {},
   "source": [
    "** need to run on every execution / after every restart of the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "id": "21ce05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "id": "e9cc5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Paths\n",
    "base_path = '.'\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join(base_path, 'workspace'),\n",
    "    \n",
    "        'IMAGE_PATH': os.path.join(base_path, 'workspace', 'images'),\n",
    "        'VIDEO_PATH': os.path.join(base_path, 'workspace', 'videos'),\n",
    "        'MODEL_PATH': os.path.join(base_path, 'workspace', 'models'),\n",
    "    \n",
    "    'LIB': os.path.join(base_path, 'lib')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "id": "fbb6ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "files = {\n",
    "    'REQUIREMENTS': os.path.join(base_path, 'workspace', 'requirements.txt')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "id": "5b2ed1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_path(path: str) -> bool:\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix': # Unix-based systems\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':    # Windows systems\n",
    "            !mkdir {path}\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "                \n",
    "for path in paths.values():\n",
    "    build_path(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb94f5",
   "metadata": {},
   "source": [
    "# 2. Installation of Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93c887",
   "metadata": {},
   "source": [
    "Please perform the following in command line:\n",
    "\n",
    "`pip install -r workspace/requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6544e1b2",
   "metadata": {},
   "source": [
    "# 3. Model Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b6104a",
   "metadata": {},
   "source": [
    "## 3.1 Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd0f93",
   "metadata": {},
   "source": [
    "** need to run on every execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "id": "2730810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "id": "5f35df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(os.path.join(paths['MODEL_PATH'], 'yolov8n.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc7a2ca",
   "metadata": {},
   "source": [
    "## Display Styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "id": "fd1d06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "id": "56eb496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import colorsys\n",
    "import math\n",
    "\n",
    "def to_rgb(h, s, v):\n",
    "    return [int(256*i) for i in colorsys.hsv_to_rgb(h,s,v)]\n",
    "\n",
    "def gen_color():\n",
    "    h,v,s = random.random(), 0.75+random.random()/4.0, .8\n",
    "    r,g,b = to_rgb(h,s,v)\n",
    "    return (b,g,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "id": "5bb16f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_COLOR = {_cls: gen_color() for _cls in classNames}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d8b47",
   "metadata": {},
   "source": [
    "## 3.2 Applying on Static Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3acd2",
   "metadata": {},
   "source": [
    "** Prerequisite: Sections 1.1, 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e11bf03",
   "metadata": {},
   "source": [
    "### Parameters / Image File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "id": "87d7d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '3.png'\n",
    "img_path = os.path.join(paths['IMAGE_PATH'], file_path)\n",
    "\n",
    "# or directly do img_path = (some path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ebac7",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "id": "8a8abd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\kht3327\\_Projects\\Previous Work\\ObjectDetection-v1\\workspace\\images\\3.png: 384x640 15 cars, 8 motorcycles, 53.3ms\n",
      "Speed: 2.5ms preprocess, 53.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 1170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model(img_path, show=False)\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.convertScaleAbs(img, alpha=0.5, beta=0)\n",
    "\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "    for box in boxes:\n",
    "        _cls = classNames[int(box.cls[0])]\n",
    "        conf = float(box.conf[0])\n",
    "        \n",
    "        if conf > 0.3:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            disp_text = f'{_cls} {math.ceil((conf*100))/100}'\n",
    "\n",
    "            # adding rectangles to the image\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), BOX_COLOR[_cls], 2)\n",
    "\n",
    "            cv2.putText(img, disp_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, BOX_COLOR[_cls], 2)\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d11109",
   "metadata": {},
   "source": [
    "## 3.3 Applying on Live Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05012f",
   "metadata": {},
   "source": [
    "** Prerequisite: Sections 1.1, 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "id": "4ecab62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "id": "98ca8425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bikes.mp4\n",
      "cars.mp4\n",
      "mask\n",
      "motorbikes.mp4\n",
      "people.mp4\n",
      "ppe-1.mp4\n",
      "ppe-2.mp4\n",
      "ppe-3.mp4\n"
     ]
    }
   ],
   "source": [
    "if os.name=='posix':\n",
    "    !ls {os.path.join(paths['VIDEO_PATH'])}\n",
    "if os.name=='nt':\n",
    "    !dir /b {os.path.join(paths['VIDEO_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f3691",
   "metadata": {},
   "source": [
    "## 3.4 Task 1: Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba95e82",
   "metadata": {},
   "source": [
    "** Prerequisite: Sections 1.1, 3.1, 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf2287",
   "metadata": {},
   "source": [
    "### Parameters / Video File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "id": "312aaeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_name = 'cars.mp4'\n",
    "vid_path = os.path.join(paths['VIDEO_PATH'], vid_name)\n",
    "\n",
    "# or directly do vid_path = (some path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e04815",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "id": "e3610eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 cars, 1 truck, 49.1ms\n",
      "Speed: 1.1ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 40.2ms\n",
      "Speed: 1.5ms preprocess, 40.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 42.3ms\n",
      "Speed: 1.1ms preprocess, 42.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 36.8ms\n",
      "Speed: 1.5ms preprocess, 36.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 37.3ms\n",
      "Speed: 1.0ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 bus, 39.9ms\n",
      "Speed: 0.5ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 bus, 1 truck, 41.7ms\n",
      "Speed: 1.6ms preprocess, 41.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(vid_path)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "hei = DEF_HEIGHT = 600\n",
    "pause = False\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == ord(' '):\n",
    "        pause = not pause\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break    \n",
    "    \n",
    "    if pause:    \n",
    "        continue    \n",
    "        \n",
    "    success, img = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    h, w, _ = img.shape\n",
    "    aspect_ratio = w / h\n",
    "    wid = int(hei * aspect_ratio)\n",
    "    \n",
    "    results = model(img, stream=True, show=False)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            cls = classNames[int(box.cls[0])]\n",
    "            conf = float(box.conf[0])\n",
    "            \n",
    "            if conf > 0.3:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                disp_text = f'{cls} {math.ceil((conf*100))/100}'\n",
    "\n",
    "                # adding rectangles to the image\n",
    "                cv2.rectangle(img, (x1,y1), (x2,y2), BOX_COLOR[cls], 2)\n",
    "\n",
    "                cv2.putText(img, disp_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, BOX_COLOR[cls], 2)\n",
    "\n",
    "    # cv2.resizeWindow('image', wid, hei)\n",
    "    cv2.imshow('image', img)\n",
    "    \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9e5d7",
   "metadata": {},
   "source": [
    "## 3.5 Task 2: Instance Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ece4bc",
   "metadata": {},
   "source": [
    "** Prerequisite: Sections 1.1, 3.1, 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "id": "107c7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "id": "771e2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_color(id: int):\n",
    "    h,v,s = id/100 % 1, 0.75 + (id/1000 % 1) / 4, 0.5\n",
    "    r,g,b = to_rgb(h,s,v)\n",
    "    return (b,g,r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47b265d",
   "metadata": {},
   "source": [
    "### 3.5.1 Method 1:  Abewley Sort Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "id": "4ac4526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## References: \n",
    "##   - https://github.com/abewley/sort\n",
    "##   - https://arxiv.org/pdf/1602.00763.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "id": "17f4c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the library from github\n",
    "paths['LIB_SORT'] = os.path.join(paths['LIB'], 'abewley_sort')\n",
    "if build_path(paths['LIB_SORT']):\n",
    "    !git clone https://github.com/abewley/sort {paths['LIB_SORT']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "id": "1f6b7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "import sys\n",
    "sys.path.append(paths['LIB_SORT'])\n",
    "from sort import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "id": "77d063a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking using the Abewley Sort library\n",
    "## max_age: the number of frames where the item is lost so that we discard the item\n",
    "## iou: intersection over union, measures how good the bounding box matches with the ground truth\n",
    "tracker = Sort(max_age=20, min_hits=1, iou_threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "id": "0d820f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 cars, 1 truck, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 39.7ms\n",
      "Speed: 1.1ms preprocess, 39.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 38.9ms\n",
      "Speed: 2.1ms preprocess, 38.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 38.0ms\n",
      "Speed: 0.5ms preprocess, 38.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 48.8ms\n",
      "Speed: 1.0ms preprocess, 48.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(vid_path)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "hei = DEF_HEIGHT = 600\n",
    "pause = False\n",
    "\n",
    "try: \n",
    "    while True:\n",
    "        key = cv2.waitKey(1)\n",
    "        if key & 0xFF == ord(' '):\n",
    "            pause = not pause\n",
    "        if key & 0xFF == ord('q'):\n",
    "            break    \n",
    "\n",
    "        if pause:    \n",
    "            continue    \n",
    "\n",
    "        success, img = cap.read()\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        h, w, _ = img.shape\n",
    "        aspect_ratio = w / h\n",
    "        wid = int(hei * aspect_ratio)\n",
    "\n",
    "        results = model(img, stream=True, show=False)\n",
    "\n",
    "        # tracker detections array init\n",
    "        detections = np.empty((0, 5))\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                cls = classNames[int(box.cls[0])]\n",
    "                conf = float(box.conf[0]) # box.conf[0] is a Tensor float format (NOT a float)\n",
    "\n",
    "                if conf > 0.2:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    disp_text = f'{cls} {math.ceil((conf*100))/100}'\n",
    "\n",
    "                    # adding rectangles to the image\n",
    "                    # cv2.rectangle(img, (x1,y1), (x2,y2), BOX_COLOR[cls], 2)\n",
    "\n",
    "                    cv2.putText(img, disp_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, BOX_COLOR[cls], 2)\n",
    "\n",
    "                    # adding the rect into the tracker detection list\n",
    "                    currentArray = np.array([x1, y1, x2, y2, conf])\n",
    "                    detections = np.vstack((detections, currentArray))\n",
    "\n",
    "        # Update the tracker (follows the format np.empty((0,5)): [x1,y1,x2,y2,confidence] -> [x1,y1,x2,y2,id])\n",
    "        tracker_results = tracker.update(detections)\n",
    "\n",
    "        for r in tracker_results:\n",
    "            x1, y1, x2, y2, Id = r\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # adding rectangles to the image\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), get_id_color(Id), 2)\n",
    "\n",
    "            cv2.putText(img, f'{int(Id)}', (x1, y1-25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, get_id_color(Id), 2)\n",
    "\n",
    "        cv2.resizeWindow('image', wid, hei)\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7888e5",
   "metadata": {},
   "source": [
    "### 3.5.2 Method 2: Custom Instancing Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "id": "b67aaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only works in low-speed environment\n",
    "# the algorithm works for O(n**2)\n",
    "\n",
    "class InstanceDetector:\n",
    "    \n",
    "    def __init__(self, maxage=5, checkage=2, strict_detection=True):\n",
    "        self.maxage = maxage\n",
    "        self.checkage = checkage\n",
    "        self.strict_detection = strict_detection\n",
    "        self.instances = dict() # format: {id: [cx, cy, w/2, h/2, disappeared_frame_count], {cls: conf, ...}}\n",
    "        self.instance_cnt = 1\n",
    "\n",
    "    def transform(self, detection=np.empty((6,))):\n",
    "        x1, y1, x2, y2, cls, conf = detection\n",
    "        cx, cy, hw, hh = (x1+x2)/2, (y1+y2)/2, (x1-x2)/2, (y1-y2)/2\n",
    "        return np.array([cx, cy, hw, hh, cls, conf, -1])\n",
    "        \n",
    "    def update(self, detections=np.empty((0,6))):\n",
    "        \"\"\"\n",
    "        Required input format: [x1, y1, x2, y2, class, conf]\n",
    "        \"\"\"\n",
    "        try:\n",
    "            transformed = np.apply_along_axis(self.transform, 1, detections)\n",
    "        except:\n",
    "            transformed = np.empty((0,7))\n",
    "        \"\"\"\n",
    "        Required transformed format: [cx, cy, hw, hh, class, conf, -1]\n",
    "        \"\"\"\n",
    "        \n",
    "        instances = dict(self.instances)\n",
    "        for new_instance in transformed:\n",
    "            cx, cy, hw, hh, cls, conf, _ = new_instance\n",
    "            area = hw * hh\n",
    "            aspect = hw / hh\n",
    "            \n",
    "            new_instance = np.array([cx, cy, hw, hh, -1])\n",
    "            min_sqd = -1\n",
    "            min_instance = -1\n",
    "            \n",
    "            destroyed = False\n",
    "            \n",
    "            for Id in instances:\n",
    "                old_instance, labels = instances[Id]\n",
    "                ocx, ocy, ohw, ohh, age = old_instance\n",
    "                oarea = ohw * ohh\n",
    "                oaspect = ohw / ohh\n",
    "                dx = cx - ocx\n",
    "                dy = cy - ocy\n",
    "                \n",
    "                area_ratio = area / oarea\n",
    "                d_aspect = aspect / oaspect\n",
    "                d_aspect = 1 / d_aspect if d_aspect < 1 else d_aspect\n",
    "                sqdist = dx ** 2 + dy ** 2 + (d_aspect-1)\n",
    "                \n",
    "                if abs(dx) > max(abs(ohw), abs(hw)) * 2 or abs(dy) > max(abs(ohh), abs(hh)) * 2:\n",
    "                    continue\n",
    "                elif not 0.01 < area_ratio < 100 or d_aspect > 5 or age > self.checkage:\n",
    "                    destroyed = True\n",
    "                    continue\n",
    "                elif self.strict_detection and age == -1  and (abs(dx) > max(abs(ohw), abs(hw)) * .2 or abs(dy) > max(abs(ohh), abs(hh)) * .2):\n",
    "                    continue\n",
    "                    \n",
    "                min_sqd = sqdist if min_sqd == -1 else min(min_sqd, sqdist)\n",
    "                if min_sqd == sqdist:\n",
    "                    min_instance = Id\n",
    "                    destroyed = False\n",
    "                \n",
    "            if min_instance != -1 and min_sqd < new_instance[2]**2+new_instance[3]**2:\n",
    "                old_instance, labels = self.instances[min_instance]\n",
    "                labels[cls] = max(labels[cls], conf) if cls in labels else conf\n",
    "                self.instances[min_instance] = new_instance, labels\n",
    "            elif not destroyed:\n",
    "                self.instances[self.instance_cnt] = new_instance, {cls: conf}\n",
    "                self.instance_cnt += 1\n",
    "        \n",
    "        for Id in self.instances:\n",
    "            self.instances[Id][0][-1] += 1\n",
    "        self.instances = {Id: instance for Id, instance in self.instances.items() if instance[0][-1] < self.maxage}\n",
    "                \n",
    "        \"\"\"\n",
    "        Required output format: [cx, cy, hw, hh, cls, conf, disappeared_frame_count]\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "id": "1d33e094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 cars, 1 truck, 50.6ms\n",
      "Speed: 1.5ms preprocess, 50.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 45.0ms\n",
      "Speed: 1.7ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 40.6ms\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 42.2ms\n",
      "Speed: 2.5ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 41.7ms\n",
      "Speed: 1.4ms preprocess, 41.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(vid_path)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "hei = DEF_HEIGHT = 600\n",
    "pause = False\n",
    "\n",
    "# tracker init\n",
    "detector = InstanceDetector(maxage=5)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        key = cv2.waitKey(1)\n",
    "        if key & 0xFF == ord(' '):\n",
    "            pause = not pause\n",
    "        if key & 0xFF == ord('q'):\n",
    "            break    \n",
    "\n",
    "        if pause:    \n",
    "            continue    \n",
    "\n",
    "        success, img = cap.read()\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        h, w, _ = img.shape\n",
    "        aspect_ratio = w / h\n",
    "        wid = int(hei * aspect_ratio)\n",
    "\n",
    "        results = model(img, stream=True, show=False)\n",
    "\n",
    "        # tracker detections array init\n",
    "        detections = np.empty((0, 6))\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                icls = int(box.cls[0])\n",
    "                cls = classNames[icls]\n",
    "                conf = float(box.conf[0])\n",
    "\n",
    "                if conf > 0.05:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    disp_text = f'{cls} {math.ceil((conf*100))/100}'\n",
    "\n",
    "                    # adding rectangles to the image\n",
    "                    # cv2.rectangle(img, (x1+2,y1+2), (x2-2,y2-2), BOX_COLOR[cls], 2)\n",
    "\n",
    "                    # cv2.putText(img, disp_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, BOX_COLOR[cls], 2)\n",
    "\n",
    "                    # adding the rect into the tracker detection list\n",
    "                    currentArray = np.array([x1, y1, x2, y2, icls, conf])\n",
    "                    detections = np.vstack((detections, currentArray))\n",
    "\n",
    "         # Update the tracker \n",
    "        detector_results = detector.update(detections)\n",
    "\n",
    "        for Id in detector_results:\n",
    "            instance, labels = detector_results[Id]\n",
    "            cx, cy, hw, hh, age = instance\n",
    "\n",
    "            labels = sorted(labels.items(), key=lambda item:item[1], reverse=True)\n",
    "            labels = [f'{classNames[int(icls)]} {math.ceil((conf*100))/100}' for icls, conf in labels]\n",
    "\n",
    "            if age != 0:\n",
    "                continue\n",
    "\n",
    "            #cls = classNames[int(icls)]\n",
    "            x1, y1, x2, y2 = int(cx+hw), int(cy+hh), int(cx-hw), int(cy-hh)\n",
    "            disp_text = f'{labels}'#f'{cls} {math.ceil((conf*100))/100}'\n",
    "\n",
    "            # adding rectangles to the image\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), get_id_color(Id), 2)\n",
    "\n",
    "            cv2.putText(img, f'{int(Id)}', (x1, y1-25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, get_id_color(Id), 2)\n",
    "            cv2.putText(img, disp_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, get_id_color(Id), 2)\n",
    "\n",
    "        cv2.resizeWindow('image', wid, hei)\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49310a31",
   "metadata": {},
   "source": [
    "## 3.6 Task 3: Car Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba5d09b",
   "metadata": {},
   "source": [
    "** Prerequisite: Sections 1.1, 3.1, 3.3, 3.5 (header), 3.5.2\n",
    "\n",
    "** In this section, every sub-sections requires the execution of every sub-section before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "id": "3d607511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths['FIG_PATH'] = os.path.join(paths['WORKSPACE_PATH'], 'figs')\n",
    "paths['FIG_PATH_CARCOUNTER'] = os.path.join(paths['FIG_PATH'], 'car_counter')\n",
    "\n",
    "build_path(paths['FIG_PATH_CARCOUNTER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "id": "75add567",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'car': \n",
    "        {\n",
    "             'vidname': 'cars.mp4',\n",
    "             'limits': \n",
    "                 {\n",
    "                     ((250, 363), (675, 363)): {'color':(50,50,255), 'format':'{}', 'position': (255, 100)}\n",
    "                 }, \n",
    "             'recoglist': ['car', 'truck', 'bus', 'motorbike'],\n",
    "             'maskpng': 'car_mask.png',\n",
    "             'labelpng': 'car_counter_label.png',\n",
    "             'labelpos': (0, 0),\n",
    "             'playback': 1\n",
    "        },\n",
    "    'mall': \n",
    "        {\n",
    "             'vidname': 'people.mp4',\n",
    "             'limits': \n",
    "                 {\n",
    "                     ((103, 161), (296, 161)): {'color':(50,255,50), 'format':'{}', 'position': (929, 345)}, # up\n",
    "                     ((470, 297), (673, 297)): {'color':(50,50,255), 'format':'{}', 'position': (1191, 345)} # down\n",
    "                 }, \n",
    "             'recoglist': ['person'],\n",
    "             'maskpng': 'people_mask.png', \n",
    "             'labelpng': 'people_counter_label.png',\n",
    "             'labelpos': (730, 260),\n",
    "             'playback': 3\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "id": "28b03f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "option = 'car'\n",
    "nomask = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "id": "bfeee8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = options[option]\n",
    "vidname, limits, recoglist, maskpng = _data['vidname'], _data['limits'], _data['recoglist'], _data['maskpng']\n",
    "labelpng, labelpos = os.path.join(paths['FIG_PATH_CARCOUNTER'], _data['labelpng']), _data['labelpos']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d327b",
   "metadata": {},
   "source": [
    "### 3.6.1 Overlap Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "id": "f3183a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overlap(limit: tuple[tuple[int]], rect: list[4]) -> bool:\n",
    "    \"\"\"\n",
    "    Input format requirement: \n",
    "     - limit: [(x1, y1), (x2, y2)]\n",
    "     - rect:  [x1, y1, x2, y2]\n",
    "    \"\"\"\n",
    "    x1, x2 = limit\n",
    "    x1, y = x1\n",
    "    x2, _ = x2\n",
    "    x_bmin, x_bmax = min(x1, x2), max(x1, x2) # line bound coords\n",
    "    \n",
    "    x1, y1, x2, y2 = rect\n",
    "    xmin, xmax = min(x1, x2), max(x1, x2)\n",
    "    ymin, ymax = min(y1, y2), max(y1, y2)\n",
    "    \n",
    "    return not (ymax < y or ymin > y or xmax < x_bmin or xmin > x_bmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88fbd5",
   "metadata": {},
   "source": [
    "### 3.6.2 Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "id": "638649e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths['MASK_PATH'] = os.path.join(paths['VIDEO_PATH'], 'mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef8e1f3",
   "metadata": {},
   "source": [
    "** The mask must be of the same size as the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "id": "af57c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.imread(os.path.join(paths['MASK_PATH'], maskpng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "id": "75ef0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for masking, do\n",
    "# masked = cv2.bitwise_and(img, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1b210",
   "metadata": {},
   "source": [
    "### 3.6.3 Playback Speed Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "id": "7b150e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Playback:\n",
    "    def __init__(self, playback_speed=1):\n",
    "        \"\"\"\n",
    "        Note: playback speed must be > 1 in this version.\n",
    "        \"\"\"\n",
    "        self.playback_speed = playback_speed\n",
    "        self.frame_cnt = 0\n",
    "        self.actual_cnt = 0\n",
    "    \n",
    "    def step(self):\n",
    "        self.frame_cnt += 1\n",
    "        if self.frame_cnt > self.actual_cnt * self.playback_speed:\n",
    "            self.actual_cnt += 1\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "id": "f66b0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "playback_speed = _data['playback'] if 'playback' in _data else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c68c3a",
   "metadata": {},
   "source": [
    "### 3.6.4 Showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "id": "a55cf88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 39.0ms\n",
      "Speed: 1.1ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 41.1ms\n",
      "Speed: 0.5ms preprocess, 41.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 39.9ms\n",
      "Speed: 1.6ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 39.9ms\n",
      "Speed: 1.5ms preprocess, 39.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 37.9ms\n",
      "Speed: 1.1ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 36.8ms\n",
      "Speed: 1.1ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(os.path.join(paths['VIDEO_PATH'], vidname))\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "hei = DEF_HEIGHT = 600\n",
    "pause = False\n",
    "\n",
    "# tracker init\n",
    "detector = InstanceDetector(maxage=5, strict_detection=False)\n",
    "\n",
    "detected = {limit: set() for limit in limits}\n",
    "\n",
    "playback = Playback(playback_speed=playback_speed)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        key = cv2.waitKey(1)\n",
    "        if key & 0xFF == ord(' '):\n",
    "            pause = not pause\n",
    "        if key & 0xFF == ord('q'):\n",
    "            break    \n",
    "\n",
    "        if pause:    \n",
    "            continue    \n",
    "\n",
    "        success, img = cap.read()\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "        if not playback.step():\n",
    "            continue\n",
    "\n",
    "        h, w, _ = img.shape\n",
    "        aspect_ratio = w / h\n",
    "        wid = int(hei * aspect_ratio)\n",
    "\n",
    "        masked_img = cv2.bitwise_and(img, mask) if not nomask else img\n",
    "        results = model(masked_img, stream=True, show=False)\n",
    "        \n",
    "        labelimg = cv2.imread(labelpng, cv2.IMREAD_UNCHANGED)\n",
    "        img = cvzone.overlayPNG(img, labelimg, labelpos)\n",
    "\n",
    "        # tracker detections array init\n",
    "        detections = np.empty((0, 6))\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                icls = int(box.cls[0])\n",
    "                cls = classNames[icls]\n",
    "                conf = float(box.conf[0])\n",
    "\n",
    "                if conf > 0.05 and cls in recoglist:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    disp_text = f'{cls} {math.ceil((conf*100))/100}'\n",
    "\n",
    "                    # adding the rect into the tracker detection list\n",
    "                    currentArray = np.array([x1, y1, x2, y2, icls, conf])\n",
    "                    detections = np.vstack((detections, currentArray))\n",
    "\n",
    "         # Update the tracker \n",
    "        detector_results = detector.update(detections)\n",
    "        \n",
    "        for limit in limits:\n",
    "            cv2.line(img, limit[0], limit[1], limits[limit]['color'], 2)\n",
    "\n",
    "        for Id in detector_results:\n",
    "            instance, labels = detector_results[Id]\n",
    "            cx, cy, hw, hh, age = instance\n",
    "\n",
    "            labels = sorted(labels.items(), key=lambda item:item[1], reverse=True)\n",
    "            labels = [f'{classNames[int(icls)]} {math.ceil((conf*100))/100}' for icls, conf in labels]\n",
    "\n",
    "            if age != 0:\n",
    "                continue\n",
    "\n",
    "            #cls = classNames[int(icls)]\n",
    "            x1, y1, x2, y2 = int(cx+hw), int(cy+hh), int(cx-hw), int(cy-hh)\n",
    "            disp_text = f\"{' '.join(labels)}\"\n",
    "            \n",
    "            for limit in limits:\n",
    "                if check_overlap(limit, [x1, y1, x2, y2]):\n",
    "                    detected[limit].add(Id)\n",
    "\n",
    "            # adding rectangles to the image\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), get_id_color(Id), 2)\n",
    "            for limit in limits:\n",
    "                if Id in detected[limit]:                \n",
    "                    cv2.rectangle(img, (x1+2,y1+2), (x2-2,y2-2), limits[limit]['color'], 2)\n",
    "\n",
    "            cv2.putText(img, f'{int(Id)}', (x1, y1-25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, get_id_color(Id), 2)\n",
    "            cv2.putText(img, disp_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, get_id_color(Id), 2)\n",
    "\n",
    "        for limit in limits:\n",
    "            cv2.putText(\n",
    "                img, \n",
    "                limits[limit]['format'].format(len(detected[limit])), \n",
    "                limits[limit]['position'], \n",
    "                cv2.FONT_HERSHEY_PLAIN, 5, limits[limit]['color'], 7\n",
    "            )    \n",
    "        \n",
    "        cv2.resizeWindow('image', wid, hei)\n",
    "        cv2.imshow('image', img)\n",
    "finally:  \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310f094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe54b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
